-- Migration pour le Système de Modération Avancé
-- Implémentation complète selon les user stories admin avec IA et modération humaine

-- Table principale pour la file de modération
CREATE TABLE IF NOT EXISTS moderation_queue (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  type VARCHAR(50) NOT NULL CHECK (type IN (
    'review', 'property', 'message', 'user_profile', 'dispute'
  )),
  content_id UUID,
  content JSONB NOT NULL,

  -- Statut et priorité
  moderation_status VARCHAR(50) NOT NULL DEFAULT 'pending' CHECK (moderation_status IN (
    'pending', 'in_review', 'approved', 'rejected', 'flagged'
  )),
  priority VARCHAR(20) NOT NULL DEFAULT 'medium' CHECK (priority IN (
    'low', 'medium', 'high', 'urgent'
  )),

  -- Détection automatique
  auto_flagged BOOLEAN DEFAULT FALSE,
  flag_reasons TEXT[],
  ai_confidence DECIMAL(5,2) CHECK (ai_confidence >= 0 AND ai_confidence <= 100),
  human_review_required BOOLEAN DEFAULT TRUE,

  -- Analyse IA
  sentiment_score DECIMAL(3,2) CHECK (sentiment_score >= -1 AND sentiment_score <= 1),
  toxicity_score DECIMAL(5,2) CHECK (toxicity_score >= 0 AND toxicity_score <= 100),
  spam_probability DECIMAL(5,2) CHECK (spam_probability >= 0 AND spam_probability <= 100),
  personal_info_detected BOOLEAN DEFAULT FALSE,
  inappropriate_content BOOLEAN DEFAULT FALSE,
  detected_keywords TEXT[],
  ai_suggested_action VARCHAR(50),
  ai_reasoning TEXT,

  -- Traitement
  reviewed_at TIMESTAMPTZ,
  reviewed_by UUID REFERENCES auth.users(id),
  moderation_notes TEXT,
  final_action VARCHAR(50),

  -- Timestamps
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Table pour les règles de modération automatique
CREATE TABLE IF NOT EXISTS moderation_rules (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(100) NOT NULL,
  description TEXT,
  rule_type VARCHAR(50) NOT NULL CHECK (rule_type IN (
    'keyword', 'pattern', 'ai_threshold', 'user_report', 'velocity'
  )),

  -- Configuration de la règle
  config JSONB NOT NULL DEFAULT '{}',

  -- Conditions et actions
  conditions JSONB NOT NULL DEFAULT '{}',
  actions JSONB NOT NULL DEFAULT '{}',

  -- Gestion
  is_active BOOLEAN DEFAULT TRUE,
  priority INTEGER DEFAULT 1,
  created_by UUID REFERENCES auth.users(id),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Table pour l'historique des analyses IA
CREATE TABLE IF NOT EXISTS ai_analysis_history (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  moderation_item_id UUID REFERENCES moderation_queue(id) ON DELETE CASCADE,

  -- Scores de l'analyse
  sentiment_score DECIMAL(3,2),
  toxicity_score DECIMAL(5,2),
  spam_probability DECIMAL(5,2),
  confidence_score DECIMAL(5,2),

  -- Détections
  personal_info_detected BOOLEAN,
  inappropriate_content BOOLEAN,
  hate_speech_detected BOOLEAN,
  harassment_detected BOOLEAN,
  spam_detected BOOLEAN,

  -- Keywords et patterns détectés
  detected_keywords TEXT[],
  detected_patterns TEXT[],

  -- Métadonnées
  model_version VARCHAR(50),
  processing_time_ms INTEGER,
  analyzed_at TIMESTAMPTZ DEFAULT NOW()
);

-- Table pour les statistiques de modération
CREATE TABLE IF NOT EXISTS moderation_stats (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  date DATE NOT NULL,
  content_type VARCHAR(50),

  -- Compteurs
  total_submitted INTEGER DEFAULT 0,
  auto_approved INTEGER DEFAULT 0,
  auto_rejected INTEGER DEFAULT 0,
  human_reviewed INTEGER DEFAULT 0,
  final_approved INTEGER DEFAULT 0,
  final_rejected INTEGER DEFAULT 0,

  -- Métriques de performance
  avg_processing_time_hours DECIMAL(8,2),
  ai_accuracy_percentage DECIMAL(5,2),
  false_positive_rate DECIMAL(5,2),

  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(date, content_type)
);

-- Fonction pour ajouter un élément à la file de modération
CREATE OR REPLACE FUNCTION add_to_moderation_queue(
  p_type VARCHAR(50),
  p_content_id UUID,
  p_content JSONB,
  p_priority VARCHAR(20) DEFAULT 'medium',
  p_auto_flag BOOLEAN DEFAULT FALSE
)
RETURNS UUID
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  queue_id UUID;
  immediate_action VARCHAR(50);
BEGIN
  -- Ajouter à la file de modération
  INSERT INTO moderation_queue (
    type, content_id, content, priority, auto_flagged
  ) VALUES (
    p_type, p_content_id, p_content, p_priority, p_auto_flag
  ) RETURNING id INTO queue_id;

  -- Analyse IA automatique si disponible
  PERFORM analyze_content_with_ai(queue_id);

  -- Vérifier s'il y a une action immédiate à prendre
  SELECT ai_suggested_action INTO immediate_action
  FROM moderation_queue
  WHERE id = queue_id;

  -- Si l'IA est très confante, traiter automatiquement
  IF immediate_action = 'approve' AND p_auto_flag = FALSE THEN
    PERFORM process_moderation_item(queue_id, 'approve', 'Auto-apprové par IA', NULL);
  ELSIF immediate_action = 'reject' AND p_auto_flag = TRUE THEN
    PERFORM process_moderation_item(queue_id, 'reject', 'Auto-rejet par IA - contenu inapproprié', NULL);
  END IF;

  RETURN queue_id;
END;
$$;

-- Fonction pour analyser le contenu avec IA (simulation)
CREATE OR REPLACE FUNCTION analyze_content_with_ai(
  p_queue_id UUID
)
RETURNS BOOLEAN
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  content_to_analyze JSONB;
  content_text TEXT;
  ai_result RECORD;
BEGIN
  -- Récupérer le contenu à analyser
  SELECT content INTO content_to_analyze
  FROM moderation_queue
  WHERE id = p_queue_id;

  -- Extraire le texte pour analyse
  content_text := COALESCE(
    content_to_analyze->>'comment',
    content_to_analyze->>'description',
    content_to_analyze->>'message',
    content_to_analyze->>'title',
    ''
  );

  -- Simuler l'analyse IA (à remplacer par un appel réel à une API)
  -- Analyse de sentiment (-1 à 1)
  ai_result.sentiment_score := (RANDOM() * 2 - 1)::DECIMAL(3,2);

  -- Analyse de toxicité (0 à 100)
  ai_result.toxicity_score := (RANDOM() * 100)::DECIMAL(5,2);

  -- Probabilité de spam (0 à 100)
  ai_result.spam_probability := (RANDOM() * 100)::DECIMAL(5,2);

  -- Détection de contenu inapproprié
  ai_result.inappropriate_content := ai_result.toxicity_score > 70 OR ai_result.spam_probability > 80;

  -- Détection d'informations personnelles (simulation basique)
  ai_result.personal_info_detected := (
    content_text ~* '\b\d{2,4}[-\s]?\d{2,4}[-\s]?\d{2,4}\b' OR  -- Téléphone
    content_text ~* '\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b' OR  -- Email
    content_text ~* '\b\d{4}\s?\d{4}\s?\d{4}\s?\d{4}\b'  -- Carte de crédit
  );

  -- Score de confiance (basé sur la longueur et la complexité)
  ai_result.confidence_score := CASE
    WHEN LENGTH(content_text) > 100 THEN 85 + (RANDOM() * 15)::DECIMAL(5,2)
    WHEN LENGTH(content_text) > 50 THEN 75 + (RANDOM() * 20)::DECIMAL(5,2)
    ELSE 65 + (RANDOM() * 25)::DECIMAL(5,2)
  END;

  -- Mots-clés détectés (simulation)
  IF ai_result.toxicity_score > 50 THEN
    ai_result.detected_keywords := ARRAY['toxic', 'inapproprié'];
  ELSIF ai_result.spam_probability > 50 THEN
    ai_result.detected_keywords := ARRAY['spam', 'promotion'];
  ELSE
    ai_result.detected_keywords := ARRAY[]::TEXT[];
  END IF;

  -- Action suggérée
  IF ai_result.confidence_score > 90 AND NOT ai_result.inappropriate_content THEN
    ai_result.suggested_action := 'approve';
  ELSIF ai_result.confidence_score > 90 AND ai_result.inappropriate_content THEN
    ai_result.suggested_action := 'reject';
  ELSE
    ai_result.suggested_action := 'flag_for_review';
  END IF;

  -- Mettre à jour l'élément avec les résultats de l'IA
  UPDATE moderation_queue SET
    sentiment_score = ai_result.sentiment_score,
    toxicity_score = ai_result.toxicity_score,
    spam_probability = ai_result.spam_probability,
    personal_info_detected = ai_result.personal_info_detected,
    inappropriate_content = ai_result.inappropriate_content,
    detected_keywords = ai_result.detected_keywords,
    ai_confidence = ai_result.confidence_score,
    ai_suggested_action = ai_result.suggested_action,
    ai_reasoning = 'Analyse basée sur les patterns linguistiques et le contexte',
    human_review_required = ai_result.confidence_score < 85 OR ai_result.inappropriate_content,
    updated_at = NOW()
  WHERE id = p_queue_id;

  -- Logger l'analyse IA
  INSERT INTO ai_analysis_history (
    moderation_item_id, sentiment_score, toxicity_score,
    spam_probability, confidence_score, personal_info_detected,
    inappropriate_content, detected_keywords,
    model_version, processing_time_ms
  ) VALUES (
    p_queue_id,
    ai_result.sentiment_score,
    ai_result.toxicity_score,
    ai_result.spam_probability,
    ai_result.confidence_score,
    ai_result.personal_info_detected,
    ai_result.inappropriate_content,
    ai_result.detected_keywords,
    'v1.0',
    150  -- Simulation de 150ms
  );

  RETURN TRUE;
END;
$$;

-- Fonction pour traiter un élément de modération
CREATE OR REPLACE FUNCTION process_moderation_item(
  p_item_id UUID,
  p_action VARCHAR(50),
  p_notes TEXT DEFAULT NULL,
  p_ai_confidence_override DECIMAL(5,2) DEFAULT NULL
)
RETURNS BOOLEAN
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  current_user_id UUID := auth.uid();
  item_record RECORD;
  is_admin BOOLEAN;
BEGIN
  -- Vérifier si l'utilisateur est admin
  SELECT EXISTS(
    SELECT 1 FROM user_roles
    WHERE user_id = current_user_id
    AND role IN ('admin', 'super_admin')
  ) INTO is_admin;

  IF NOT is_admin THEN
    RAISE EXCEPTION 'Permission refusée: rôle admin requis';
  END IF;

  -- Récupérer l'élément à traiter
  SELECT * INTO item_record
  FROM moderation_queue
  WHERE id = p_item_id;

  IF NOT FOUND THEN
    RAISE EXCEPTION 'Élément de modération non trouvé: %', p_item_id;
  END IF;

  -- Mettre à jour l'élément
  UPDATE moderation_queue SET
    moderation_status = CASE
      WHEN p_action = 'approve' THEN 'approved'
      WHEN p_action = 'reject' THEN 'rejected'
      WHEN p_action = 'flag' THEN 'flagged'
      ELSE 'pending'
    END,
    reviewed_at = NOW(),
    reviewed_by = current_user_id,
    moderation_notes = p_notes,
    final_action = p_action,
    ai_confidence = COALESCE(p_ai_confidence_override, ai_confidence),
    updated_at = NOW()
  WHERE id = p_item_id;

  -- Logger l'action de modération
  INSERT INTO admin_audit_logs (
    admin_id, action_type, target_type, target_id, action_metadata
  ) VALUES (
    current_user_id,
    'content_moderated',
    'moderation_queue',
    p_item_id,
    jsonb_build_object(
      'action', p_action,
      'content_type', item_record.type,
      'auto_flagged', item_record.auto_flagged,
      'ai_confidence', COALESCE(p_ai_confidence_override, item_record.ai_confidence),
      'notes', p_notes
    )
  );

  -- Mettre à jour les statistiques
  PERFORM update_moderation_stats(item_record.type, p_action);

  RETURN TRUE;
END;
$$;

-- Fonction pour obtenir les statistiques de modération
CREATE OR REPLACE FUNCTION get_moderation_stats()
RETURNS TABLE (
  total_items BIGINT,
  pending_items BIGINT,
  approved_items BIGINT,
  rejected_items BIGINT,
  flagged_items BIGINT,
  auto_flagged_items BIGINT,
  human_reviewed_items BIGINT,
  average_processing_time DECIMAL(8,2),
  this_month_items BIGINT
)
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
BEGIN
  RETURN QUERY
  SELECT
    COUNT(*) as total_items,
    COUNT(*) FILTER (WHERE moderation_status = 'pending') as pending_items,
    COUNT(*) FILTER (WHERE moderation_status = 'approved') as approved_items,
    COUNT(*) FILTER (WHERE moderation_status = 'rejected') as rejected_items,
    COUNT(*) FILTER (WHERE moderation_status = 'flagged') as flagged_items,
    COUNT(*) FILTER (WHERE auto_flagged = TRUE) as auto_flagged_items,
    COUNT(*) FILTER (WHERE auto_flagged = FALSE) as human_reviewed_items,
    AVG(
      CASE
        WHEN reviewed_at IS NOT NULL AND created_at IS NOT NULL
        THEN EXTRACT(EPOCH FROM (reviewed_at - created_at)) / 3600
        ELSE NULL
      END
    ) as average_processing_time,
    COUNT(*) FILTER (
      WHERE created_at >= DATE_TRUNC('month', CURRENT_DATE)
    ) as this_month_items
  FROM moderation_queue;
END;
$$;

-- Fonction pour mettre à jour les statistiques de modération
CREATE OR REPLACE FUNCTION update_moderation_stats(
  p_content_type VARCHAR(50),
  p_action VARCHAR(50)
)
RETURNS VOID
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
BEGIN
  INSERT INTO moderation_stats (
    date, content_type, total_submitted, final_approved, final_rejected
  ) VALUES (
    CURRENT_DATE,
    p_content_type,
    1,
    CASE WHEN p_action = 'approve' THEN 1 ELSE 0 END,
    CASE WHEN p_action = 'reject' THEN 1 ELSE 0 END
  )
  ON CONFLICT (date, content_type) DO UPDATE SET
    total_submitted = moderation_stats.total_submitted + 1,
    final_approved = moderation_stats.final_approved +
      CASE WHEN p_action = 'approve' THEN 1 ELSE 0 END,
    final_rejected = moderation_stats.final_rejected +
      CASE WHEN p_action = 'reject' THEN 1 ELSE 0 END;
END;
$$;

-- Trigger pour mettre à jour le timestamp updated_at
CREATE OR REPLACE FUNCTION update_moderation_timestamp()
RETURNS TRIGGER
LANGUAGE plpgsql
AS $$
BEGIN
  NEW.updated_at = NOW();
  RETURN NEW;
END;
$$;

-- Créer les triggers
CREATE TRIGGER update_moderation_queue_timestamp
  BEFORE UPDATE ON moderation_queue
  FOR EACH ROW
  EXECUTE FUNCTION update_moderation_timestamp();

CREATE TRIGGER update_moderation_rules_timestamp
  BEFORE UPDATE ON moderation_rules
  FOR EACH ROW
  EXECUTE FUNCTION update_moderation_timestamp();

-- RLS Policies
ALTER TABLE moderation_queue ENABLE ROW LEVEL SECURITY;
ALTER TABLE moderation_rules ENABLE ROW LEVEL SECURITY;
ALTER TABLE ai_analysis_history ENABLE ROW LEVEL SECURITY;
ALTER TABLE moderation_stats ENABLE ROW LEVEL SECURITY;

-- Policy: Seuls les admins peuvent voir la file de modération
CREATE POLICY "Admins can view moderation queue" ON moderation_queue
FOR SELECT USING (
  EXISTS (
    SELECT 1 FROM user_roles
    WHERE user_id = auth.uid()
    AND role IN ('admin', 'super_admin')
  )
);

-- Policy: Seuls les admins peuvent modifier la file de modération
CREATE POLICY "Admins can update moderation queue" ON moderation_queue
FOR UPDATE USING (
  EXISTS (
    SELECT 1 FROM user_roles
    WHERE user_id = auth.uid()
    AND role IN ('admin', 'super_admin')
  )
);

-- Policy: Seuls les admins peuvent voir les règles de modération
CREATE POLICY "Admins can view moderation rules" ON moderation_rules
FOR SELECT USING (
  EXISTS (
    SELECT 1 FROM user_roles
    WHERE user_id = auth.uid()
    AND role IN ('admin', 'super_admin')
  )
);

-- Policy: Seuls les admins peuvent gérer les règles de modération
CREATE POLICY "Admins can manage moderation rules" ON moderation_rules
FOR ALL USING (
  EXISTS (
    SELECT 1 FROM user_roles
    WHERE user_id = auth.uid()
    AND role IN ('admin', 'super_admin')
  )
);

-- Policy: Seuls les admins peuvent voir l'historique IA
CREATE POLICY "Admins can view AI analysis history" ON ai_analysis_history
FOR SELECT USING (
  EXISTS (
    SELECT 1 FROM user_roles
    WHERE user_id = auth.uid()
    AND role IN ('admin', 'super_admin')
  )
);

-- Policy: Seuls les admins peuvent voir les statistiques
CREATE POLICY "Admins can view moderation stats" ON moderation_stats
FOR SELECT USING (
  EXISTS (
    SELECT 1 FROM user_roles
    WHERE user_id = auth.uid()
    AND role IN ('admin', 'super_admin')
  )
);

-- Index pour optimiser les performances
CREATE INDEX IF NOT EXISTS idx_moderation_queue_status ON moderation_queue(moderation_status);
CREATE INDEX IF NOT EXISTS idx_moderation_queue_type ON moderation_queue(type);
CREATE INDEX IF NOT EXISTS idx_moderation_queue_priority ON moderation_queue(priority);
CREATE INDEX IF NOT EXISTS idx_moderation_queue_created_at ON moderation_queue(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_moderation_queue_auto_flagged ON moderation_queue(auto_flagged);
CREATE INDEX IF NOT EXISTS idx_moderation_stats_date_type ON moderation_stats(date, content_type);
CREATE INDEX IF NOT EXISTS idx_ai_analysis_history_moderation_id ON ai_analysis_history(moderation_item_id);

-- Créer des règles de modération par défaut
INSERT INTO moderation_rules (name, description, rule_type, config, conditions, actions, priority) VALUES
(
  'Contenu haineux',
  'Détecte automatiquement le contenu haineux et discriminatoire',
  'keyword',
  '{"keywords": ["haineux", "raciste", "discriminatoire", "xénophobe"], "match_type": "any"}',
  '{"min_confidence": 0.8}',
  '{"action": "flag", "priority": "urgent"}',
  1
),
(
  'Spam et promotion',
  'Détecte le spam et les promotions non sollicitées',
  'pattern',
  '{"patterns": [" cliquez ici ", " promotion ", " offre spéciale ", " gagnez maintenant "]}',
  '{"min_matches": 2}',
  '{"action": "flag", "priority": "medium"}',
  2
),
(
  'Informations personnelles',
  'Détecte la divulgation d informations personnelles',
  'ai_threshold',
  '{"detect_emails": true, "detect_phones": true, "detect_addresses": true}',
  '{"min_confidence": 0.7}',
  '{"action": "flag", "priority": "high"}',
  3
) ON CONFLICT DO NOTHING;

-- Commentaires sur les tables
COMMENT ON TABLE moderation_queue IS 'File d attente pour la modération de contenu avec IA';
COMMENT ON TABLE moderation_rules IS 'Règles de modération automatique configurables';
COMMENT ON TABLE ai_analysis_history IS 'Historique des analyses IA pour apprentissage et audit';
COMMENT ON TABLE moderation_stats IS 'Statistiques agrégées de la modération';

-- Commentaires sur les fonctions principales
COMMENT ON FUNCTION add_to_moderation_queue() IS 'Ajoute un élément à la file de modération avec analyse IA automatique';
COMMENT ON FUNCTION process_moderation_item() IS 'Traite un élément de modération manuellement';
COMMENT ON FUNCTION analyze_content_with_ai() IS 'Analyse le contenu avec IA pour détection automatique';
COMMENT ON FUNCTION get_moderation_stats() IS 'Retourne les statistiques agrégées de modération';